---
title: "Knowledge & Motivation Correlations-2"
execute:
  echo: true
  warning: false
format:
  html: 
    grid:
      sidebar-width: 220px
      body-width: 1200px
      margin-width: 170px
      gutter-width: 1.0rem
  hugo-md:
    include: true
    html-math-method: mathjax
    output-file: cor_hugo2.md
  # pdf: 
  #   documentclass: article
  #   papersize: letter
  #   toc: false
  #   fontsize: 10pt
  #   linestretch: 1.5
  #   geometry:
  #     - top=.5in     
  #     - bottom=.5in  
  #     - left=.5in    
  #     - right=.25in  
  #     - heightrounded
---


This study set out to assess how prior survey instruments on sustainable behaviors, knowledge, and attitudes correlate.Many studies on environmental behavior measure people's motivation to show sustainable behavior and classify them as being highly or lowly motivated, and their knowledge about what the right behavior would look like. An example would be recycling.


# Read data 

```{r}
pacman::p_load(dplyr,purrr,tidyr,here, haven,tibble,ggplot2,ggh4x,lme4,knitr,kableExtra,gt,pander,flextable,ggh4x,psych,corrplot,factoextra)
options(digits=2, scipen=999, dplyr.summarise.inform=FALSE)

library(gridExtra)
library(factoextra)
library(mgcv)
library(lavaan)
library(CCA)
library(qgraph)
library(rpart)
library(rpart.plot)
library(mclust)
library(tidyLPA)

select = dplyr::select

source(here("scripts","survey_functions.R"))

draw <- readRDS(here("data","draw.rds"))
dinst <- readRDS(here("data","dinst.rds"))

# Attari Energy Survey (Part 1)
aes1 <- draw |> select(id,ATT01:ATT18)
aes2 <- dinst |> select(id,ATT01:ATT18)
aes_combined <- bind_rows(aes1, aes2)

att_useSave <- draw |> select(id,ATT19:ATT33)
att_useSave2 <- dinst |> select(id,ATT19:ATT33)
att2_combined <- bind_rows(att_useSave, att_useSave2)

els1 <- draw |> select(id,ELS01:ELS08)
els2 <- dinst |> select(id,ELS01:ELS08)
els <- bind_rows(els1,els2)

rs1 <- draw |> select(id,RS01:RS06)
rs2 <- dinst |> select(id,RS01:RS06)
rs <- bind_rows(rs1,rs2)

attari1 <- analyze_attari_survey_part1(aes_combined)
attari2_scores <- analyze_attari_survey(att2_combined)
els_scores <- analyze_els_survey(els)
rs_scores <- analyze_recycling_survey(rs)

# Combine all scores into one dataframe
combined_scores <- attari1 %>%
  left_join(attari2_scores, by="id") %>%
  left_join(els_scores, by="id") %>%
  left_join(rs_scores, by="id")

# Rename columns for clarity
names(combined_scores) <- c("id", "perceived_difficulty", "numeracy", 
                          "energy_use", "energy_save", 
                          "els_accuracy", "els_score",
                          "env_attitude", "env_attitude_z",
                          "pol_conservatism", "pol_conservatism_z")


```


# preview data

```{r}

combined_scores |> head(5) |> kable() |> kable_styling("striped", full_width = F)

```


# 1a

 ```{r}

 # 1. Cluster Analysis

# Prepare data for clustering (select relevant variables and scale)
cluster_data <- combined_scores %>%
  select(perceived_difficulty, numeracy, energy_use, energy_save, els_score, env_attitude_z, pol_conservatism_z) %>%
  na.omit() %>%
  scale()

# Determine optimal number of clusters using the elbow method
fviz_nbclust(cluster_data, kmeans, method = "wss") +
  labs(title = "Elbow Method for Optimal k", x = "Number of Clusters k")


 ```



```{r}

# Perform k-means clustering (e.g., with 3 clusters)
set.seed(123)
km_result <- kmeans(cluster_data, centers = 3, nstart = 25)

# Visualize the clusters
fviz_cluster(km_result, data = cluster_data,
             geom = "point",
             ellipse.type = "convex",
             ggtheme = theme_bw()) +
  labs(title = "K-means Clustering of Subjects")

```


```{r}


# Add cluster assignments to the main dataframe
combined_scores$cluster <- as.factor(km_result$cluster)

# 2. Enhanced Factor Analysis

# Scree plot to determine the number of factors
fa_data <- combined_scores %>%
  select(perceived_difficulty, numeracy, energy_use, energy_save, els_score, env_attitude_z, pol_conservatism_z) %>%
  na.omit()
scree(fa_data)


# Perform factor analysis with, e.g., 3 factors
fa_result <- fa(fa_data, nfactors = 2, rotate = "varimax")
print(fa_result, cut = 0.3, sort = TRUE)



# 3. Enhanced Regression Models
# Model predicting ELS from motivation, controlling for other knowledge scores
model_els_enhanced <- lm(els_score ~ perceived_difficulty + env_attitude_z + pol_conservatism_z +
                           numeracy + energy_use + energy_save, data = combined_scores)
summary(model_els_enhanced)


# 4. Interaction Effects in Regression
# Example: Interaction between environmental attitude and perceived difficulty on ELS
model_interaction <- lm(els_score ~ perceived_difficulty * env_attitude_z, data = combined_scores)
summary(model_interaction)

# Visualize the interaction (example)
ggplot(combined_scores, aes(x = perceived_difficulty, y = els_score, color = env_attitude_z)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(title = "Interaction of Perceived Difficulty and Environmental Attitude on ELS",
       x = "Perceived Difficulty",
       y = "Energy Literacy Score") +
  theme_minimal()
```





# 2a

```{r}
#| fig-width: 10
#| fig-height: 8


combined_df <- attari1 %>%
  full_join(attari2_scores, by = "id") %>%
  full_join(els_scores,       by = "id") %>%
  full_join(rs_scores,        by = "id")


# 1. Create knowledge profiles using cluster analysis
knowledge_vars <- combined_df %>% 
  select(numeracy_score, relative_energy_use_score, 
         relative_energy_save_score, els)

set.seed(123)
clusters <- kmeans(scale(knowledge_vars), centers=3)

# Add cluster membership to data
combined_df$knowledge_cluster <- as.factor(clusters$cluster)

# Compare motivation scores across clusters
cluster_comparison <- combined_df %>%
  group_by(knowledge_cluster) %>%
  summarise(
    mean_env_attitude = mean(env_attitude, na.rm=TRUE),
    mean_difficulty = mean(perceived_difficulty_score, na.rm=TRUE)
  )

# 2. Test for non-linear relationships
gam_model <- gam(els ~ s(env_attitude) + s(perceived_difficulty_score), 
                 data=combined_df)

# 3. Create interaction model between knowledge and motivation
interaction_model <- lm(els ~ env_attitude * perceived_difficulty_score + 
                         numeracy_score, data=combined_df)






# 1. Enhanced Correlation Plot
cor_matrix <- combined_df %>%
  select(numeracy_score, relative_energy_use_score, 
         relative_energy_save_score, els, 
         perceived_difficulty_score, env_attitude, 
         pol_conservatism_z) %>%
  cor(use = "pairwise.complete.obs")

corrplot(cor_matrix, 
         method = "color",
         type = "upper",
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 45,
         diag = FALSE,
         col = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200))

# 2. Knowledge Profile Clustering
# Standardize knowledge variables
knowledge_vars <- combined_df %>%
  select(numeracy_score, relative_energy_use_score, 
         relative_energy_save_score, els) %>%
  scale()

# Determine optimal number of clusters
set.seed(123)
wss <- sapply(1:10, function(k) {
  kmeans(knowledge_vars, centers=k)$tot.withinss
})

# Perform k-means clustering
k <- 3  # Based on elbow plot inspection
clusters <- kmeans(knowledge_vars, centers=k)

# Add cluster membership to data
combined_df$knowledge_cluster <- as.factor(clusters$cluster)

# Visualize clusters
pca_result <- prcomp(knowledge_vars)
cluster_df <- data.frame(
  PC1 = pca_result$x[,1],
  PC2 = pca_result$x[,2],
  Cluster = combined_df$knowledge_cluster
)

# Create cluster visualization
p_clusters <- ggplot(cluster_df, aes(x=PC1, y=PC2, color=Cluster)) +
  geom_point(alpha=0.6) +
  theme_minimal() +
  labs(title="Knowledge Profiles Clustering",
       x="First Principal Component",
       y="Second Principal Component")
p_clusters

# 3. Non-linear GAM Analysis
gam_model <- gam(els ~ s(env_attitude) + s(perceived_difficulty_score), 
                 data=combined_df)

# Create prediction grid for GAM visualization
env_grid <- seq(min(combined_df$env_attitude, na.rm=TRUE),
                max(combined_df$env_attitude, na.rm=TRUE),
                length.out=100)
diff_grid <- seq(min(combined_df$perceived_difficulty_score, na.rm=TRUE),
                 max(combined_df$perceived_difficulty_score, na.rm=TRUE),
                 length.out=100)

# Predict ELS scores
pred_env <- predict(gam_model, 
                   newdata=data.frame(env_attitude=env_grid,
                                    perceived_difficulty_score=mean(combined_df$perceived_difficulty_score, na.rm=TRUE)))
pred_diff <- predict(gam_model,
                    newdata=data.frame(perceived_difficulty_score=diff_grid,
                                     env_attitude=mean(combined_df$env_attitude, na.rm=TRUE)))

# Create GAM plots
p_gam_env <- ggplot() +
  geom_line(aes(x=env_grid, y=pred_env), color="blue") +
  geom_point(data=combined_df, aes(x=env_attitude, y=els), alpha=0.2) +
  theme_minimal() +
  labs(title="Non-linear Relationship: Environmental Attitude and Energy Literacy",
       x="Environmental Attitude",
       y="Energy Literacy Score")

p_gam_diff <- ggplot() +
  geom_line(aes(x=diff_grid, y=pred_diff), color="red") +
  geom_point(data=combined_df, aes(x=perceived_difficulty_score, y=els), alpha=0.2) +
  theme_minimal() +
  labs(title="Non-linear Relationship: Perceived Difficulty and Energy Literacy",
       x="Perceived Difficulty Score",
       y="Energy Literacy Score")

#p_gam_diff


# 4. Knowledge-Motivation Interaction Analysis
interaction_model <- lm(els ~ env_attitude * perceived_difficulty_score + 
                         numeracy_score, data=combined_df)

summary(interaction_model)

# Create interaction plot data
env_levels <- quantile(combined_df$env_attitude, probs=c(0.25, 0.75), na.rm=TRUE)
diff_seq <- seq(min(combined_df$perceived_difficulty_score, na.rm=TRUE),
                max(combined_df$perceived_difficulty_score, na.rm=TRUE),
                length.out=100)

# Arrange all plots
grid.arrange(p_clusters, p_gam_env, p_gam_diff, ncol=2)

# Print statistical summaries
summary(gam_model)
summary(interaction_model)

# Cluster profile analysis
cluster_profiles <- combined_df %>%
  group_by(knowledge_cluster) %>%
  summarise(
    mean_numeracy = mean(numeracy_score, na.rm=TRUE),
    mean_energy_use = mean(relative_energy_use_score, na.rm=TRUE),
    mean_energy_save = mean(relative_energy_save_score, na.rm=TRUE),
    mean_els = mean(els, na.rm=TRUE),
    mean_env_attitude = mean(env_attitude, na.rm=TRUE),
    mean_difficulty = mean(perceived_difficulty_score, na.rm=TRUE),
    n = n()
  )

print(cluster_profiles)

```

{{< pagebreak >}}

# 3a

```{r}

# Example: K-means clustering on knowledge + motivation
# Subset your knowledge & motivation columns
cluster_data <- combined_df %>%
  select(numeracy_score, relative_energy_use_score, relative_energy_save_score,
         els, perceived_difficulty_score, env_attitude, pol_conservatism) %>%
  na.omit()

# Scale them
cluster_data_scaled <- scale(cluster_data)

# Decide on number of clusters (e.g. 2–5) – use e.g. Elbow method
fviz_nbclust(cluster_data_scaled, kmeans, method = "wss")

# Suppose we choose 3 clusters as a demonstration
set.seed(123)
km_result <- kmeans(cluster_data_scaled, centers = 3, nstart = 25)

# Add cluster membership back into the original data
cluster_data$cluster <- factor(km_result$cluster)

# Visualize clusters in 2D (using PCA behind the scenes)
fviz_cluster(km_result, data = cluster_data_scaled,
             geom = "point", ellipse.type = "convex") +
  theme_minimal() +
  labs(title = "K-means Clusters of Knowledge & Motivation Variables")



# 1. Grab relevant variables
cluster_data <- combined_df %>%
  select(numeracy_score, relative_energy_use_score, relative_energy_save_score,
         els, perceived_difficulty_score, env_attitude, pol_conservatism) %>%
  na.omit()

# 2. Standardize/scale them
cluster_data_scaled <- scale(cluster_data)

# 3. Determine the optimal number of clusters (Elbow or Silhouette methods)
fviz_nbclust(cluster_data_scaled, kmeans, method = "wss") +
  theme_minimal()

# 4. Run k-means with your chosen number of clusters (say k = 3)
set.seed(123)
km_res <- kmeans(cluster_data_scaled, centers = 3, nstart = 25)

# 5. Visualize
fviz_cluster(km_res, data = cluster_data_scaled,
             geom = "point", ellipse.type = "convex") +
  theme_minimal() +
  labs(title = "K-means Clusters of Knowledge & Motivation Variables")

# 6. Inspect cluster means
cluster_centers <- as.data.frame(km_res$centers)
colnames(cluster_centers) <- colnames(cluster_data)
cluster_centers
```

{{< pagebreak >}}

```{r}
#| fig-width: 10
#| fig-height: 8

# Example of hierarchical clustering if that is preferred
dist_mat <- dist(cluster_data_scaled, method = "euclidean")
hc_res <- hclust(dist_mat, method = "ward.D2")
plot(hc_res, main = "Dendrogram of Hierarchical Clustering")

# Cut tree at chosen k
clusters <- cutree(hc_res, k = 3)
table(clusters)
```


```{r}

# Example mediation: knowledge -> perceived_difficulty -> env_attitude
model_mediation <- '
  # direct effect
  env_attitude ~ c*els
  # mediator
  perceived_difficulty_score ~ a*els
  env_attitude ~ b*perceived_difficulty_score
  # indirect effect
  ab := a*b
  # total effect
  total := c + (a*b)
'

fit_mediation <- sem(model_mediation, data = combined_df, missing="fiml")
summary(fit_mediation, fit.measures=TRUE, standardized=TRUE, rsquare=TRUE)
```



----

{{< pagebreak >}}

# 4a

```{r}

combined_scores <- combined_df %>%
  mutate(
    # Example composite for knowledge: average of (z-scored) numeracy, 
    # energy_use, energy_save, ELS. 
    # (You can also sum them, but average is convenient.)
    composite_knowledge = rowMeans(
      cbind(numeracy_score, relative_energy_use_score, 
            relative_energy_save_score, els),
      na.rm = FALSE  # If a row has missing for any item, result = NA
    ),
    
    # Example composite for motivation: 
    # env_attitude might be already in a favorable direction, but if 
    # perceived_difficulty is "difficulty," consider reversing so that 
    # higher = "less difficulty" = "higher motivation."
    # For example: reverse_diff = (-1)*perceived_difficulty_score
    # Then average with env_attitude (if you want them combined).
    # If you are including pol_conservatism as well, you must decide 
    # how to handle that in the composite. Possibly reverse-coded 
    # so that higher # = more liberal or more "pro-environment" stance. 
    # (It's your theoretical call.)
    
    # For now, let's do a small composite with environmental attitude 
    # and reversed difficulty:
    reverse_diff = -1 * perceived_difficulty_score,
    
    composite_motivation = rowMeans(
      cbind(env_attitude, reverse_diff), 
      na.rm = FALSE
    )
  )

# We'll create a small data frame with just the two composites, 
# removing any incomplete cases
cluster_data <- combined_scores %>%
  select(composite_knowledge, composite_motivation) %>%
  na.omit()

# Decide on number of clusters "k". Let’s try k = 3:
set.seed(123) 
km3 <- kmeans(cluster_data, centers = 3, nstart = 25)

# Inspect results
km3

# Visualize
fviz_cluster(km3, data = cluster_data,
             geom = "point", ellipse.type = "convex") +
  theme_minimal() +
  labs(title = "K-means (k=3) Clustering on Knowledge vs. Motivation")


combined_scores$cluster <- factor(km3$cluster)

# Compare mean knowledge & motivation by cluster
combined_scores %>%
  group_by(cluster) %>%
  summarize(
    n = n(),
    mean_knowledge = mean(composite_knowledge, na.rm = TRUE),
    mean_motivation = mean(composite_motivation, na.rm = TRUE)
  ) 


```




-------

{{< pagebreak >}}

# 5a

```{r}
#| fig-width: 9
#| fig-height: 7

combined_scores <- attari1 %>%
  left_join(attari2_scores, by="id") %>%
  left_join(els_scores, by="id") %>%
  left_join(rs_scores, by="id")

# Rename columns for clarity
names(combined_scores) <- c("id", "perceived_difficulty", "numeracy", 
                          "energy_use", "energy_save", 
                          "els_accuracy", "els_score",
                          "env_attitude", "env_attitude_z",
                          "pol_conservatism", "pol_conservatism_z")

combined_scores$cluster <- as.factor(km_result$cluster)

# Create composite knowledge score
combined_scores$composite_knowledge <- rowMeans(combined_scores[, c("numeracy", "energy_use", "energy_save", "els_score")], na.rm = TRUE)

# Create standardized scores for profile analysis
profile_data <- combined_scores %>%
  select(id, cluster, numeracy, energy_use, energy_save, 
         els_score, env_attitude, perceived_difficulty) %>%
  gather(measure, value, -id, -cluster) %>%
  group_by(measure) %>%
  mutate(z_score = scale(value)[,1]) %>%
  ungroup()

# Create profile plot
ggplot(profile_data, aes(x = measure, y = z_score, color = cluster, group = cluster)) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point", size = 3) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Knowledge-Motivation Profiles by Cluster",
       x = "Measure", y = "Standardized Score")



# 2. Canonical Correlation Analysis between Knowledge and Motivation Sets
# Prepare matrices
knowledge_vars <- combined_scores %>% select(numeracy, energy_use, energy_save, els_score) %>%
  as.matrix()

motivation_vars <- combined_scores %>%
  select(env_attitude, perceived_difficulty, pol_conservatism) %>%
  as.matrix()

# Perform CCA
cc_result <- cancor(knowledge_vars, motivation_vars)

# 3. Network Analysis to Visualize Variable Relationships

# Create correlation matrix
cor_matrix <- cor(combined_scores %>%
                   select(numeracy, energy_use, energy_save, els_score,
                         env_attitude, perceived_difficulty, pol_conservatism),
                 use = "pairwise.complete.obs")

# Create network plot
qgraph(cor_matrix, 
       layout = "spring",
       groups = list(Knowledge = 1:4, Motivation = 5:7),
       color = c(rep("lightblue", 4), rep("lightgreen", 3)))


# 4. Mixed Effects Model to Account for Potential Group-Level Effects
mixed_model <- lmer(els_score ~ env_attitude + perceived_difficulty + 
                     (1|cluster), data = combined_scores)
summary(mixed_model)

# 5. Structural Equation Model for Path Analysis

# Define model
model <- '
  # Measurement model
  knowledge =~ numeracy + energy_use + energy_save + els_score
  motivation =~ env_attitude + perceived_difficulty + pol_conservatism

  # Structural model
  knowledge ~ motivation
'

# Fit model
fit <- sem(model, data = combined_scores)
summary(fit, standardized = TRUE, fit.measures = TRUE)



# 6. Classification Tree for Predicting Knowledge Levels - rpart functions
# Create binary knowledge indicator (high/low) based on median split
combined_scores$knowledge_level <- factor(ifelse(combined_scores$composite_knowledge > 
                                               median(combined_scores$composite_knowledge, na.rm = TRUE),
                                               "High", "Low"))

# Fit tree
tree_model <- rpart(knowledge_level ~ env_attitude + perceived_difficulty + 
                     pol_conservatism, data = combined_scores)

# Plot tree
rpart.plot(tree_model, extra = 1)


```



--------

{{< pagebreak >}}

# 1b

```{r}
#| fig-width: 10
#| fig-height: 8



lpa_model <- Mclust(cluster_data_scaled)
summary(lpa_model)
plot(lpa_model, "BIC")


can_cor <- cancor(select(combined_scores, numeracy, energy_use, energy_save),
                  select(combined_scores, env_attitude_z, perceived_difficulty))
print(can_cor$cor)


fviz_nbclust(cluster_data_scaled, cluster::pam, method = "silhouette") +
  labs(title = "Silhouette Method for Optimal k")


sem_model <- '
  knowledge =~ numeracy + energy_use + energy_save + els_accuracy
  motivation =~ env_attitude_z + perceived_difficulty
  knowledge ~ motivation
'
fit <- sem(sem_model, data = combined_scores)
summary(fit, standardized = TRUE)



combined_scores %>%
  group_by(cluster) %>%
  summarise(across(c(numeracy, env_attitude_z), 
                   list(mean = mean, sd = sd)))



plot(lpa_model, "BIC") # Visualize model selection
lpa_3class <- Mclust(cluster_data_scaled, G=3) # Force 3-class solution
summary(lpa_3class, parameters=TRUE)
plot(lpa_3class, what="classification") # Visualize classification



# 2. Interpret canonical variables
cancor_loadings <- can_cor$xcoef %>% 
  as.data.frame() %>%
  rownames_to_column("variable") %>%
  rename(Dimension1=V1, Dimension2=V2, Dimension3=V3)
print(cancor_loadings)

# 3. Improve SEM specification
sem_improved <- '
  knowledge =~ numeracy + energy_use + energy_save + els_accuracy
  motivation =~ env_attitude_z + perceived_difficulty
  knowledge ~ motivation
  els_accuracy ~~ energy_use # Add residual covariance
'
fit_improved <- sem(sem_improved, data=combined_scores)
summary(fit_improved, fit.measures=TRUE)


# 4. Validate clusters with outcomes
combined_scores %>%
  group_by(cluster) %>%
  summarise(recycling_rate = mean(env_attitude_z, na.rm=TRUE),
            energy_behavior = mean(energy_save, na.rm=TRUE)) %>%
  pivot_longer(-cluster, names_to="outcome") %>%
  ggplot(aes(x=cluster, y=value, fill=outcome)) +
  geom_col(position="dodge") +
  labs(title="Cluster Validation Through Behavioral Outcomes")

```

{{< pagebreak >}}

# 2b


```{r}
#| fig-width: 10
#| fig-height: 8


# Combine all items into a single dataframe
all_items <- full_join(aes_combined, att2_combined, by = "id") %>%
  full_join(els, by = "id") %>%
  full_join(rs, by = "id")

# Select only item columns for factor analysis
item_columns <- setdiff(names(all_items), "id")
item_data <- all_items[, item_columns]

# Perform factor analysis
fa_items <- fa(item_data, nfactors = 5, rotate = "varimax")  # Adjust nfactors as needed
print(fa_items, cut = 0.3, sort = TRUE)


model <- '
  # Measurement model
  Knowledge =~ numeracy + energy_use + energy_save + els_score
  Motivation =~ env_attitude_z + perceived_difficulty

  # Structural model
  Knowledge ~ Motivation
'

fit <- sem(model, data = combined_scores)
summary(fit, fit.measures = TRUE, standardized = TRUE)


# Example LPA (using tidyLPA)
lpa_data <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score, env_attitude_z, perceived_difficulty) %>%
  na.omit() |> 
  # convert all to numeric
    mutate_all(as.numeric)

lpa_results <- lpa_data %>%
  estimate_profiles(n_profiles = 1:5) %>% # Estimate models with 1-5 profiles
  compare_solutions(statistics = c("AIC", "BIC"))

plot(lpa_results)

# Determine optimal k using silhouette method
fviz_nbclust(cluster_data_scaled, kmeans, method = "silhouette") +
  labs(title = "Silhouette Method for Optimal k")

```




-----

# 3b

```{r}
#| fig-width: 11
#| fig-height: 8

# 1) Create a correlation matrix of the key knowledge & motivation subscales
#    ensuring no duplicates (e.g., pick either 'env_attitude' or 'env_attitude_z').

cor_vars <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score,
         perceived_difficulty, env_attitude, pol_conservatism)

# 2) Compute correlations
cor_matrix <- cor(cor_vars, use = "pairwise.complete.obs")

# 3) Visualize
corrplot::corrplot(cor_matrix, method = "color", type="upper", 
                   tl.col="black", addCoef.col="black")

fa_data <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score,
         perceived_difficulty, env_attitude, pol_conservatism) %>%
  na.omit()

fa_result <- fa(fa_data, nfactors = 2, rotate = "varimax", fm = "ml")
print(fa_result, cut=0.3, sort=TRUE)



model_motivation <- lm(env_attitude ~ els_score + numeracy + pol_conservatism,
                       data=combined_scores)
summary(model_motivation)


model_knowledge <- lm(els_score ~ perceived_difficulty + env_attitude + pol_conservatism,
                      data=combined_scores)
summary(model_knowledge)


knowledge_only <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score) %>%
  na.omit() %>%
  scale()

set.seed(123)
# Decide k with elbow or silhouette
fviz_nbclust(knowledge_only, kmeans, method="wss")

km_knowl <- kmeans(knowledge_only, centers=3, nstart=25)
fviz_cluster(km_knowl, data = knowledge_only)


all_vars <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score,
         perceived_difficulty, env_attitude, pol_conservatism) %>%
  na.omit() %>%
  scale()

set.seed(123)
fviz_nbclust(all_vars, kmeans, method="wss")

km_all <- kmeans(all_vars, centers=3, nstart=25)
fviz_cluster(km_all, data=all_vars)



```

{{< pagebreak >}}

# 4b

```{r}
#| fig-width: 11
#| fig-height: 8


# 1. Summarize clusters on an extra measure
combined_scores %>%
  group_by(cluster) %>%
  summarise(
    mean_recycling = mean(env_attitude_z, na.rm=TRUE),
    sd_recycling   = sd(env_attitude_z, na.rm=TRUE),
    n = n()
  ) %>%
  arrange(cluster)

# 2. ANOVA to test whether clusters differ significantly 
anova_result <- aov(env_attitude_z ~ cluster, data = combined_scores)
summary(anova_result)

# 3. Pairwise comparisons if ANOVA is significant
TukeyHSD(anova_result)

# Subset data to knowledge & motivation variables
lpa_data <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score, 
         perceived_difficulty, env_attitude, pol_conservatism) %>%
  na.omit() %>%
  scale()

# Model-based clustering
lpa_model <- Mclust(lpa_data)
summary(lpa_model)  # Tells you how many clusters & the type of covariance structure

# Extract membership
combined_scores$LPA_cluster <- as.factor(lpa_model$classification)
table(combined_scores$LPA_cluster)

# Compare means across the new LPA-based clusters
combined_scores %>%
  group_by(LPA_cluster) %>%
  summarise(
    across(numeracy:pol_conservatism, mean, na.rm=TRUE)
  )


```



--------

{{< pagebreak >}}

# 1c

```{r}
# Combine all individual survey items from each instrument
all_items <- bind_rows(aes_combined, att2_combined) %>%
  full_join(els, by = "id") %>%
  full_join(rs, by = "id")

# Select only item columns for analysis
item_data <- all_items %>% select(-id)

subscale_cors <- combined_scores %>%
  select(perceived_difficulty, numeracy, energy_use, energy_save,
         els_score, env_attitude_z, pol_conservatism_z) %>%
  cor(use = "pairwise.complete.obs")


# 3. Knowledge-Motivation Relationship Analyses
# Create composite scores with explicit content alignment
knowledge_vars <- c("numeracy", "energy_use", "energy_save", "els_score")
motivation_vars <- c("env_attitude_z", "perceived_difficulty")

combined_scores <- combined_scores %>%
  mutate(
    knowledge = scale(rowMeans(select(., all_of(knowledge_vars)), na.rm = TRUE)),
    motivation = scale(rowMeans(select(., all_of(motivation_vars)) * c(1, -1), na.rm = TRUE))
  )

# 3a. Bivariate Correlation
with(combined_scores, cor.test(knowledge, motivation))

# 3b. Hierarchical Regression
model <- lm(knowledge ~ motivation + pol_conservatism_z + cluster, 
            data = combined_scores)
summary(model)

# 3c. Path Analysis
path_model <- '
  motivation ~ a * knowledge
  els_score ~ b * motivation + c * knowledge
  indirect := a * b
  total := c + indirect
'
fit <- sem(path_model, data = combined_scores)
summary(fit, standardized = TRUE)

# 4. Cluster Validation by Motivation-Knowledge Profiles
ggplot(combined_scores, aes(x = knowledge, y = motivation, color = cluster)) +
  geom_point(alpha = 0.6) +
  stat_ellipse(level = 0.95) +
  labs(title = "Knowledge-Motivation Profiles by Cluster",
       x = "Standardized Knowledge Composite",
       y = "Standardized Motivation Composite") +
  theme_minimal()
```


# 2c

```{r}

# Combine key measures into correlation matrix
key_measures <- combined_scores %>%
  select(
    # Knowledge measures
    numeracy, energy_use, energy_save, els_score,
    # Motivation/attitude measures 
    env_attitude, perceived_difficulty, pol_conservatism
  ) %>%
  na.omit()

# Compute and visualize correlation matrix
cor_matrix <- cor(key_measures, use="pairwise.complete.obs")
corrplot(cor_matrix, 
         method="color",
         type="upper",
         addCoef.col = "black",
         tl.col="black",
         tl.srt=45,
         diag=FALSE,
         col=colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200))

# 2. Factor Analysis to examine underlying structure
fa_results <- fa(key_measures, nfactors=2, rotate="varimax")
print(fa_results, cut=0.3, sort=TRUE)

# 3. Create composite scores and analyze relationships
combined_scores <- combined_scores %>%
  mutate(
    # Knowledge composite (z-score mean)
    knowledge_composite = scale(rowMeans(
      cbind(scale(numeracy), scale(energy_use), 
            scale(energy_save), scale(els_score)))),
    # Motivation composite
    motivation_composite = scale(rowMeans(
      cbind(scale(env_attitude), -scale(perceived_difficulty), 
            -scale(pol_conservatism))))
  )

# 4. Profile Analysis using cluster analysis
# Standardize variables for clustering
cluster_vars <- combined_scores %>%
  select(knowledge_composite, motivation_composite) %>%
  na.omit() %>%
  scale()

# Determine optimal number of clusters
fviz_nbclust(cluster_vars, kmeans, method="silhouette")

# Perform k-means clustering
set.seed(123)
k <- 3  # Based on silhouette plot
clusters <- kmeans(cluster_vars, centers=k, nstart=25)

# Visualize clusters
fviz_cluster(clusters, data=cluster_vars,
             geom="point",
             ellipse.type="convex",
             ggtheme=theme_minimal()) +
  labs(title="Knowledge-Motivation Profiles")

# 5. Regression Analysis
# Model 1: Knowledge predicting motivation
model_1 <- lm(motivation_composite ~ knowledge_composite, data=combined_scores)

# Model 2: Controlling for demographics if available
model_2 <- lm(motivation_composite ~ knowledge_composite + pol_conservatism, 
              data=combined_scores)

summary(model_1)
summary(model_2)

# 6. Examine cluster profiles
cluster_profiles <- combined_scores %>%
  mutate(cluster = factor(clusters$cluster)) %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    mean_knowledge = mean(knowledge_composite, na.rm=TRUE),
    sd_knowledge = sd(knowledge_composite, na.rm=TRUE),
    mean_motivation = mean(motivation_composite, na.rm=TRUE),
    sd_motivation = sd(motivation_composite, na.rm=TRUE)
  )

print(cluster_profiles)

```



# 3c

```{r}
#| fig-width: 10
#| fig-height: 8

# Merge them into one "long" dataframe with all items.
all_items <- aes_combined %>%
  full_join(att2_combined, by = "id") %>%
  full_join(els,           by = "id") %>%
  full_join(rs,            by = "id")

# Inspect how many rows (should match total unique respondents if IDs match)
dim(all_items)
head(all_items)

# Alternatively, if you want only the *summarized scale scores* 
# for each instrument (as in your existing code):
#   - attari1, attari2_scores, els_scores, rs_scores 
# we can merge those:

combined_scores <- attari1 %>%
  left_join(attari2_scores, by = "id") %>%
  left_join(els_scores,     by = "id") %>%
  left_join(rs_scores,      by = "id")

# Rename columns for clarity (optional)
names(combined_scores) <- c(
  "id", 
  "perceived_difficulty",  # from Attari Part 1
  "numeracy",
  "energy_use",
  "energy_save",
  "els_accuracy",
  "els_score",
  "env_attitude",
  "env_attitude_z",
  "pol_conservatism",
  "pol_conservatism_z"
)


# 2. Examine correlations and underlying structure
# A. Correlation plot among the *scale-level* variables
cor_vars <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score,
         perceived_difficulty, env_attitude, pol_conservatism)

cor_matrix <- cor(cor_vars, use = "pairwise.complete.obs")

# Visualize correlation matrix
corrplot::corrplot(
  cor_matrix, 
  method = "color", 
  addCoef.col = "black", 
  type = "upper",
  tl.col  = "black",
  tl.srt  = 45,
  diag    = FALSE
)


# B. Factor Analysis (to see if knowledge & motivation load differently)
#    Using, e.g., 2-factor solution as a demonstration:
fa_data <- cor_vars %>%
  na.omit()

two_factor <- fa(fa_data, nfactors = 2, rotate = "varimax", fm = "ml")
print(two_factor, cut = 0.30, sort = TRUE)


# ============================================================
# 3. Inspect the relation between "motivation" and "knowledge"
# ============================================================

# --- (a) Simple regressions
# For example: Predict ELS knowledge (els_score) from motivation variables
model_els <- lm(els_score ~ env_attitude + perceived_difficulty + pol_conservatism, 
                data = combined_scores)
summary(model_els)


# --- (b) Create composites and correlate them
# Composite for "knowledge": average of numeracy, energy_use, energy_save, els_score
combined_scores <- combined_scores %>%
  mutate(
    knowledge_composite = rowMeans(
      cbind(numeracy, energy_use, energy_save, els_score), 
      na.rm = TRUE
    ),
    # For "motivation," you might choose env_attitude and reverse-coded difficulty, 
    # or some other conceptual combination. Example:
    motivation_composite = rowMeans(
      cbind(env_attitude, -1 * perceived_difficulty), 
      na.rm = TRUE
    )
  )

cor(combined_scores$knowledge_composite, combined_scores$motivation_composite,
    use = "pairwise.complete.obs")

cluster_data <- combined_scores %>%
  select(knowledge_composite, motivation_composite) %>%
  na.omit() %>%
  scale()

# Decide the number of clusters (k). Let's try k = 3 for illustration:
set.seed(123)
km_fit <- kmeans(cluster_data, centers = 3, nstart = 25)

# Visualize clusters
fviz_cluster(km_fit, data = cluster_data) +
  labs(title = "K-means Clustering on Knowledge vs. Motivation") +
  theme_minimal()

# Add cluster membership back to your main dataframe
combined_scores$km_cluster <- factor(km_fit$cluster)

# Compare mean knowledge & motivation by cluster
combined_scores %>%
  group_by(km_cluster) %>%
  summarise(
    mean_knowledge = mean(knowledge_composite, na.rm = TRUE),
    mean_motivation = mean(motivation_composite, na.rm = TRUE),
    n = n()
  )


# --- (d) Canonical Correlation Analysis (CCA)
# Splitting your knowledge vs. motivation sets

knowledge_set <- combined_scores %>%
  select(numeracy, energy_use, energy_save, els_score) %>%
  na.omit()

motivation_set <- combined_scores %>%
  select(env_attitude, perceived_difficulty, pol_conservatism) %>%
  na.omit()

# We need same rows for both sets, so do a quick align:
cca_df <- na.omit(data.frame(knowledge_set, motivation_set))
K <- cca_df[, 1:4]
M <- cca_df[, 5:7]

cca_res <- cancor(K, M)
cca_res$cor  # canonical correlations

# Inspect canonical weights and loadings
cca_res$xcoef
cca_res$ycoef

# Hypothetical model: 
#   - latent Knowledge from numeracy, energy_use, energy_save, els_score
#   - latent Motivation from env_attitude, perceived_difficulty
#   - regression: Knowledge ~ Motivation

sem_model <- '
  Knowledge =~ numeracy + energy_use + energy_save + els_score
  Motivation =~ env_attitude + perceived_difficulty
  Knowledge ~ Motivation
'
fit_sem <- sem(sem_model, data = combined_scores, missing = "fiml")  # handle missing if needed
summary(fit_sem, fit.measures = TRUE, standardized = TRUE)

```
